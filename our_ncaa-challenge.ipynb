{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-15T10:22:47.442283Z","iopub.status.busy":"2024-03-15T10:22:47.441894Z","iopub.status.idle":"2024-03-15T10:22:48.897772Z","shell.execute_reply":"2024-03-15T10:22:48.896418Z","shell.execute_reply.started":"2024-03-15T10:22:47.442249Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:48.900151Z","iopub.status.busy":"2024-03-15T10:22:48.899685Z","iopub.status.idle":"2024-03-15T10:22:48.905440Z","shell.execute_reply":"2024-03-15T10:22:48.904215Z","shell.execute_reply.started":"2024-03-15T10:22:48.900120Z"},"trusted":true},"outputs":[],"source":["input_dir= \"/kaggle/input/march-machine-learning-mania-2024/\"\n","#pd.read_csv(input_dir+\"Conferences.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["### possible features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:48.907866Z","iopub.status.busy":"2024-03-15T10:22:48.907107Z","iopub.status.idle":"2024-03-15T10:22:48.919816Z","shell.execute_reply":"2024-03-15T10:22:48.918324Z","shell.execute_reply.started":"2024-03-15T10:22:48.907811Z"},"trusted":true},"outputs":[],"source":["#point per possession \n","#PPP = Pts/Poss \n","#POSS = FGA + 0.475 x FTA - ORB + TO\n"," \n","# Ast/To ratio\n","\n","#Effective field goal percentage\n","# (FGM + 0.5 * 3PM) / FGA.\n","\n","#True shooting percentage\n","#PTS/(2*(FGA+0.44*FTA))\n","\n","#TOV percentage\n","# 100 * TOV / (FGA + 0.44 * FTA + TOV).\n","\n","#pace \n","# Minutes per Game x ((Team Possessions + Opponent Possessions) ÷ (2 x (Team Minutes Played ÷ 5)))"]},{"cell_type":"markdown","metadata":{},"source":["# MNCAA start from here\n","## MNCAA Regular Season ↓"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:48.923781Z","iopub.status.busy":"2024-03-15T10:22:48.923093Z","iopub.status.idle":"2024-03-15T10:22:49.727698Z","shell.execute_reply":"2024-03-15T10:22:49.726634Z","shell.execute_reply.started":"2024-03-15T10:22:48.923742Z"},"trusted":true},"outputs":[],"source":["# MNCAA start from here\n","M_RegularDetail= pd.read_csv(input_dir+\"MRegularSeasonDetailedResults.csv\")\n","display(M_RegularDetail)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:49.730703Z","iopub.status.busy":"2024-03-15T10:22:49.729919Z","iopub.status.idle":"2024-03-15T10:22:49.760794Z","shell.execute_reply":"2024-03-15T10:22:49.759278Z","shell.execute_reply.started":"2024-03-15T10:22:49.730664Z"},"trusted":true},"outputs":[],"source":["#MTeamConferences\n","MTeamConferences = pd.read_csv(input_dir+\"MTeamConferences.csv\")\n","MTeamConferences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:49.763466Z","iopub.status.busy":"2024-03-15T10:22:49.763073Z","iopub.status.idle":"2024-03-15T10:22:49.882949Z","shell.execute_reply":"2024-03-15T10:22:49.881537Z","shell.execute_reply.started":"2024-03-15T10:22:49.763430Z"},"trusted":true},"outputs":[],"source":["# merge M_RegularDetail with MTeamConferences\n","MTeamConferences = pd.read_csv(input_dir+\"MTeamConferences.csv\")\n","MTeamConferences = MTeamConferences.rename(columns={'TeamID':'WTeamID'})\n","M_RegularDetail_merge_MTeamConferences = pd.merge(left=M_RegularDetail,right=\\\n","                                             MTeamConferences,on=['Season','WTeamID'],\\\n","                                                  how='left')\n","M_RegularDetail_merge_MTeamConferences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:49.887211Z","iopub.status.busy":"2024-03-15T10:22:49.886860Z","iopub.status.idle":"2024-03-15T10:22:49.981540Z","shell.execute_reply":"2024-03-15T10:22:49.980265Z","shell.execute_reply.started":"2024-03-15T10:22:49.887181Z"},"trusted":true},"outputs":[],"source":["#confirm column'ConfAbbrev' without nan\n","M_RegularDetail_merge_MTeamConferences.dropna(subset='ConfAbbrev')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:49.983311Z","iopub.status.busy":"2024-03-15T10:22:49.982965Z","iopub.status.idle":"2024-03-15T10:22:49.989081Z","shell.execute_reply":"2024-03-15T10:22:49.987538Z","shell.execute_reply.started":"2024-03-15T10:22:49.983280Z"},"trusted":true},"outputs":[],"source":["pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:49.991160Z","iopub.status.busy":"2024-03-15T10:22:49.990717Z","iopub.status.idle":"2024-03-15T10:22:50.520712Z","shell.execute_reply":"2024-03-15T10:22:50.519321Z","shell.execute_reply.started":"2024-03-15T10:22:49.991125Z"},"trusted":true},"outputs":[],"source":["M_WinTeams= pd.DataFrame()\n","M_LoseTeams=pd.DataFrame()\n","\n","columns= ['Season','TeamID', 'Score', 'OppScore',\n","       'Loc', 'NumOT', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA',\n","       'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'OppFGM', 'OppFGA',\n","       'OppFGM3', 'OppFGA3', 'OppFTM', 'OppFTA', 'OppOR', 'OppDR', 'OppAst', 'OppTO',\n","       'OppStl', 'OppBlk', 'Opp PF']\n","\n","M_WinTeams[columns]= M_RegularDetail[['Season','WTeamID', 'WScore',  'LScore',\n","       'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA',\n","       'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA',\n","       'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO',\n","       'LStl', 'LBlk', 'LPF']]\n","\n","M_WinTeams[\"Win\"]=1\n","M_WinTeams[\"Loss\"]=0\n","\n","M_LoseTeams[columns]= M_RegularDetail[['Season','LTeamID', 'LScore',  'WScore',\n","       'WLoc', 'NumOT', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA',\n","       'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', 'WFGM', 'WFGA',\n","       'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO',\n","       'WStl', 'WBlk', 'WPF']]\n","\n","def change_loc(loc):\n","    if loc == 'H':\n","        return 'A'\n","    elif loc == 'A':\n","        return 'H'\n","    else:\n","        return 'N'\n","    \n","M_LoseTeams[\"Loc\"]= M_LoseTeams[\"Loc\"].apply(change_loc)\n","    \n","M_LoseTeams[\"Win\"]=0\n","M_LoseTeams [\"Loss\"]=1\n","\n","M_WinLoseTeams= pd.concat([M_WinTeams,M_LoseTeams])\n","\n","M_WinLoseTeams['H'] = (M_WinLoseTeams['Loc'] == 'H').astype(int)\n","M_WinLoseTeams['A'] = (M_WinLoseTeams['Loc'] == 'A').astype(int)\n","M_WinLoseTeams['N'] = (M_WinLoseTeams['Loc'] == 'N').astype(int)\n","M_WinLoseTeams.drop('Loc', axis=1, inplace=True)\n","\n","M_combinedTeams= M_WinLoseTeams.groupby([\"Season\",\"TeamID\"]).sum()\n","M_combinedTeams[\"Game_played\"]= M_combinedTeams[\"Win\"] + M_combinedTeams[\"Loss\"]\n","\n","display(M_combinedTeams.columns.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:50.526080Z","iopub.status.busy":"2024-03-15T10:22:50.525660Z","iopub.status.idle":"2024-03-15T10:22:50.591638Z","shell.execute_reply":"2024-03-15T10:22:50.590355Z","shell.execute_reply.started":"2024-03-15T10:22:50.526044Z"},"trusted":true},"outputs":[],"source":["M_RegularSeason_input= pd.DataFrame()\n","\n","M_RegularSeason_input[\"win_ratio\"]= M_combinedTeams[\"Win\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"ppg\"]= M_combinedTeams[\"Score\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"opp_ppg\"]= M_combinedTeams[\"OppScore\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"point_diff_per_game\"]= (M_combinedTeams[\"Score\"]-M_combinedTeams[\"OppScore\"])/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"ot_per_game\"]= M_combinedTeams[\"NumOT\"]/M_combinedTeams[\"Game_played\"]\n","\n","M_RegularSeason_input[\"FGM3pergame\"]= M_combinedTeams[\"FGM3\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"FG3ratio\"]= M_combinedTeams[\"FGM3\"]/M_combinedTeams[\"FGA3\"]\n","M_RegularSeason_input[\"FG3_allowedpergame\"]= M_combinedTeams[\"OppFGM3\"]/M_combinedTeams[\"Game_played\"]\n","\n","M_RegularSeason_input[\"FGMpergame\"]= M_combinedTeams[\"FGM\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"FGratio\"]= M_combinedTeams[\"FGM\"]/M_combinedTeams[\"FGA\"]\n","M_RegularSeason_input[\"FG_allowedpergame\"]= M_combinedTeams[\"OppFGM\"]/M_combinedTeams[\"Game_played\"]\n","\n","M_RegularSeason_input[\"FTMpergame\"]= M_combinedTeams[\"FTM\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"FTratio\"]= M_combinedTeams[\"FTM\"]/M_combinedTeams[\"FTA\"]\n","M_RegularSeason_input[\"FT_allowedpergame\"]= M_combinedTeams[\"OppFTM\"]/M_combinedTeams[\"Game_played\"]\n","\n","\n","M_RegularSeason_input[\"ORratio\"]= M_combinedTeams[\"OR\"]/(M_combinedTeams[\"OR\"]+M_combinedTeams[\"OppDR\"])\n","M_RegularSeason_input[\"DRratio\"]= M_combinedTeams[\"DR\"]/(M_combinedTeams[\"DR\"]+M_combinedTeams[\"OppOR\"])\n","\n","M_RegularSeason_input[\"Ast_per_g\"]= M_combinedTeams[\"Ast\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"To_per_g\"]= M_combinedTeams[\"TO\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"Stl_per_g\"]= M_combinedTeams[\"Stl\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"Blk_per_g\"]= M_combinedTeams[\"Blk\"]/M_combinedTeams[\"Game_played\"]\n","M_RegularSeason_input[\"Pf_per_g\"]= M_combinedTeams[\"PF\"]/M_combinedTeams[\"Game_played\"]\n","\n","\n","##\n","\n","display(M_RegularSeason_input)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:50.593784Z","iopub.status.busy":"2024-03-15T10:22:50.593361Z","iopub.status.idle":"2024-03-15T10:22:51.354858Z","shell.execute_reply":"2024-03-15T10:22:51.353598Z","shell.execute_reply.started":"2024-03-15T10:22:50.593745Z"},"trusted":true},"outputs":[],"source":["M_seeds = pd.read_csv(input_dir+\"MNCAATourneySeeds.csv\")\n","M_TourneyCompact=pd.read_csv(input_dir+\"MNCAATourneyCompactResults.csv\")\n","\n","\n","M_seeds_dict= M_seeds.set_index([\"Season\",\"TeamID\"])\n","#display(M_seeds_dict.index.values)\n","\n","M_tourney_input=pd.DataFrame()\n","\n","M_winIDs= M_TourneyCompact[\"WTeamID\"]\n","M_loseIDs=M_TourneyCompact[\"LTeamID\"]\n","M_season= M_TourneyCompact[\"Season\"]\n","\n","M_winners= pd.DataFrame()\n","M_winners[[\"Season\",\"Team1\",\"Team2\"]]= M_TourneyCompact[[\"Season\",\"WTeamID\",\"LTeamID\"]]\n","M_winners[\"Result\"]=1\n","\n","M_losers= pd.DataFrame()\n","M_losers[[\"Season\",\"Team1\",\"Team2\"]]= M_TourneyCompact[[\"Season\",\"LTeamID\",\"WTeamID\"]]\n","M_losers[\"Result\"]=0\n","\n","M_tourney_input= pd.concat([M_winners,M_losers])\n","\n","M_tourney_input= M_tourney_input[M_tourney_input[\"Season\"]>2002].reset_index(drop=True)\n","\n","#M_tourney_input\n","\n","\n","M_team1_seeds=[]\n","M_team2_seeds=[]\n","\n","for i in range(len(M_tourney_input)):\n","    idx= (M_tourney_input[\"Season\"][i], M_tourney_input[\"Team1\"][i])\n","    seed= M_seeds_dict.loc[idx].values[0]\n","    if len(seed)==4:\n","        seed= int(seed[1:-1])\n","    else:\n","        seed= int(seed[1:])\n","    M_team1_seeds.append(seed)\n","    \n","    idx= (M_tourney_input[\"Season\"][i], M_tourney_input[\"Team2\"][i])\n","    seed= M_seeds_dict.loc[idx].values[0]\n","    if len(seed)==4:\n","        seed= int(seed[1:-1])\n","    else:\n","        seed= int(seed[1:])\n","    M_team2_seeds.append(seed)\n","\n","M_tourney_input[\"Team1Seed\"]=M_team1_seeds\n","M_tourney_input[\"Team2Seed\"]=M_team2_seeds\n","\n","M_tourney_input\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:51.357855Z","iopub.status.busy":"2024-03-15T10:22:51.357033Z","iopub.status.idle":"2024-03-15T10:22:58.074263Z","shell.execute_reply":"2024-03-15T10:22:58.073293Z","shell.execute_reply.started":"2024-03-15T10:22:51.357785Z"},"trusted":true},"outputs":[],"source":["M_outscores=[]\n","\n","for i in range(len(M_tourney_input)):\n","    idx= (M_tourney_input[\"Season\"][i], M_tourney_input[\"Team1\"][i])\n","    team1score= M_RegularSeason_input.loc[idx].copy()\n","    team1score[\"Seed\"]= M_tourney_input[\"Team1Seed\"][i]\n","    \n","    idx= (M_tourney_input[\"Season\"][i], M_tourney_input[\"Team2\"][i])\n","    team2score= M_RegularSeason_input.loc[idx].copy()\n","    team2score[\"Seed\"]= M_tourney_input[\"Result\"][i]\n","    \n","    outscore= team1score-team2score\n","    outscore[\"Result\"]= M_tourney_input[\"Team2Seed\"][i]\n","    M_outscores.append(outscore)\n","    \n","M_outscores=pd.DataFrame(M_outscores)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:58.077213Z","iopub.status.busy":"2024-03-15T10:22:58.075872Z","iopub.status.idle":"2024-03-15T10:22:58.195650Z","shell.execute_reply":"2024-03-15T10:22:58.194391Z","shell.execute_reply.started":"2024-03-15T10:22:58.077173Z"},"trusted":true},"outputs":[],"source":["display(M_outscores.describe())\n","display(M_outscores)"]},{"cell_type":"markdown","metadata":{},"source":["Ray"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#point per possession \n","#PPP = Pts/Poss \n","#POSS = FGA + 0.475 x FTA - ORB + TO\n"," \n","# Ast/To ratio\n","\n","#Effective field goal percentage\n","# (FGM + 0.5 * 3PM) / FGA.\n","\n","#True shooting percentage\n","#PTS/(2*(FGA+0.44*FTA))\n","\n","#TOV percentage\n","# 100 * TOV / (FGA + 0.44 * FTA + TOV).\n","\n","#pace \n","# Minutes per Game x ((Team Possessions + Opponent Possessions) ÷ (2 x (Team Minutes Played ÷ 5)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:55:18.115342Z","iopub.status.busy":"2024-03-15T10:55:18.114640Z","iopub.status.idle":"2024-03-15T10:55:18.129490Z","shell.execute_reply":"2024-03-15T10:55:18.128132Z","shell.execute_reply.started":"2024-03-15T10:55:18.115191Z"},"trusted":true},"outputs":[],"source":["pd.set_option('display.max_columns', None)\n","# M_RegularDetail_merge_MTeamConferences.head()\n","M_RegularDetail_merge_MTeamConferences['WPPP']=M_RegularDetail_merge_MTeamConferences['WFGA']+0.475*M_RegularDetail_merge_MTeamConferences['WFTA']\n","-M_RegularDetail_merge_MTeamConferences['WOR']+M_RegularDetail_merge_MTeamConferences['WTO']\n","# M_RegularDetail_merge_MTeamConferences['WPPP']"]},{"cell_type":"markdown","metadata":{},"source":["# WNCAA start from here\n","## WNCAA tourney ↓"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:58.236177Z","iopub.status.busy":"2024-03-15T10:22:58.235738Z","iopub.status.idle":"2024-03-15T10:22:58.645064Z","shell.execute_reply":"2024-03-15T10:22:58.643732Z","shell.execute_reply.started":"2024-03-15T10:22:58.236147Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/march-machine-learning-mania-2024/WRegularSeasonDetailedResults.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_dir\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/kaggle/input/march-machine-learning-mania-2024/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m reg_det \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(input_dir\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWRegularSeasonDetailedResults.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m25\u001b[39m)\n\u001b[1;32m      4\u001b[0m display(reg_det)\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/march-machine-learning-mania-2024/WRegularSeasonDetailedResults.csv'"]}],"source":["input_dir= \"/kaggle/input/march-machine-learning-mania-2024/\"\n","reg_det = pd.read_csv(input_dir+\"WRegularSeasonDetailedResults.csv\")\n","pd.set_option('display.max_rows', 25)\n","display(reg_det)\n","seeds = pd.read_csv(input_dir+\"WNCAATourneySeeds.csv\")\n","display(seeds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:58.647066Z","iopub.status.busy":"2024-03-15T10:22:58.646695Z","iopub.status.idle":"2024-03-15T10:22:58.714941Z","shell.execute_reply":"2024-03-15T10:22:58.713737Z","shell.execute_reply.started":"2024-03-15T10:22:58.647033Z"},"trusted":true},"outputs":[],"source":["WTeamConferences = pd.read_csv(input_dir+\"WTeamConferences.csv\")\n","WTeamConferences = WTeamConferences.rename(columns={'TeamID':'TeamID'})\n","W_seeds_merge_WTeamConferences = pd.merge(left=seeds,right=\\\n","                                             WTeamConferences,on=['Season','TeamID'],\\\n","                                                  how='left')\n","\n","W_seeds_merge_WTeamConferences = pd.get_dummies(W_seeds_merge_WTeamConferences, columns=['ConfAbbrev'])\n","dummies_columns = [col for col in W_seeds_merge_WTeamConferences if 'ConfAbbrev' in col]\n","\n","W_seeds_merge_WTeamConferences[dummies_columns] = W_seeds_merge_WTeamConferences[dummies_columns].astype(int)\n","\n","W_seeds_merge_WTeamConferences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:58.717696Z","iopub.status.busy":"2024-03-15T10:22:58.716957Z","iopub.status.idle":"2024-03-15T10:22:59.088779Z","shell.execute_reply":"2024-03-15T10:22:59.087546Z","shell.execute_reply.started":"2024-03-15T10:22:58.717654Z"},"trusted":true},"outputs":[],"source":["w_Teams = pd.DataFrame()\n","l_Teams = pd.DataFrame()\n","\n","columns = ['Season', 'TeamID', 'Score', 'oppScore',\n","       'Loc', 'NumOT', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA',\n","       'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'oppFGM', 'oppFGA',\n","       'oppFGM3', 'oppFGA3', 'oppFTM', 'oppFTA', 'oppOR', 'oppDR', 'oppAst', 'oppTO',\n","       'oppStl', 'oppBlk', 'oppPF']\n","\n","w_Teams[columns] = reg_det[['Season', 'WTeamID', 'WScore', 'LScore',\n","       'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA',\n","       'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA',\n","       'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO',\n","       'LStl', 'LBlk', 'LPF']]\n","w_Teams['win'] = 1\n","w_Teams['loss'] = 0\n","\n","columns = ['Season', 'TeamID', 'Score', 'oppScore',\n","       'Loc', 'NumOT', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA',\n","       'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF', 'oppFGM', 'oppFGA',\n","       'oppFGM3', 'oppFGA3', 'oppFTM', 'oppFTA', 'oppOR', 'oppDR', 'oppAst', 'oppTO',\n","       'oppStl', 'oppBlk', 'oppPF']\n","\n","l_Teams[columns] = reg_det[['Season', 'LTeamID', 'LScore', 'WScore',\n","       'WLoc', 'NumOT', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA',\n","       'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', 'WFGM', 'WFGA',\n","       'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO',\n","       'WStl', 'WBlk', 'WPF']]\n","l_Teams['win'] = 0\n","l_Teams['loss'] = 1\n","\n","def change_loc(loc):\n","    if loc == 'H':\n","        return 'A'\n","    elif loc == 'A':\n","        return 'H'\n","    else:\n","        return 'N'\n","\n","l_Teams['Loc'] = l_Teams['Loc'].apply(change_loc)\n","\n","\n","all_teams = pd.concat([w_Teams, l_Teams])\n","display(all_teams)\n","all_teams['H'] = (all_teams['Loc'] == 'H').astype(int)\n","all_teams['A'] = (all_teams['Loc'] == 'A').astype(int)\n","all_teams['N'] = (all_teams['Loc'] == 'N').astype(int)\n","all_teams.drop('Loc', axis=1, inplace=True)\n","combined_teams = all_teams.groupby(['Season', 'TeamID']).sum()\n","combined_teams['Game_played'] = combined_teams['win'] + combined_teams['loss']\n","\n","\n","display (combined_teams)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:59.090746Z","iopub.status.busy":"2024-03-15T10:22:59.089960Z","iopub.status.idle":"2024-03-15T10:22:59.312769Z","shell.execute_reply":"2024-03-15T10:22:59.310807Z","shell.execute_reply.started":"2024-03-15T10:22:59.090712Z"},"trusted":true},"outputs":[],"source":["reg_input = pd.DataFrame()\n","reg_input['win_ratio'] = combined_teams['win'] / combined_teams['Game_played']\n","reg_input['ppg'] = combined_teams['Score'] / combined_teams['Game_played']\n","reg_input['opp_ppg'] = combined_teams['oppScore'] / combined_teams['Game_played']\n","reg_input['pts_ratio'] = combined_teams['Score'] / combined_teams['oppScore']\n","reg_input['ot_per_game'] = combined_teams['NumOT'] / combined_teams['Game_played']\n","\n","reg_input['FGM3pergame'] = combined_teams['FGM3'] / combined_teams['Game_played']\n","reg_input['FG3ratio'] = combined_teams['FGM3'] / combined_teams['FGA3']\n","reg_input['FG3_allowedpergame'] = combined_teams['oppFGM3'] / combined_teams['Game_played']\n","\n","reg_input['FGMpergame'] = combined_teams['FGM'] / combined_teams['Game_played']\n","reg_input['FGratio'] = combined_teams['FGM'] / combined_teams['FGA']\n","reg_input['FG_allowedpergame'] = combined_teams['oppFGM'] / combined_teams['Game_played']\n","\n","reg_input['FTMpergame'] = combined_teams['FTM'] / combined_teams['Game_played']\n","reg_input['FTratio'] = combined_teams['FTM'] / combined_teams['FTA']\n","reg_input['FT_allowedpergame'] = combined_teams['oppFTM'] / combined_teams['Game_played']\n","\n","reg_input['ORratio'] = combined_teams['OR']/(combined_teams['OR']+combined_teams['oppDR'])\n","reg_input['DRratio'] = combined_teams['DR']/(combined_teams['DR']+combined_teams['oppOR'])\n","\n","reg_input['Ast_per_g'] = combined_teams['Ast']/combined_teams['Game_played']\n","reg_input['To_per_g'] = combined_teams['TO']/combined_teams['Game_played']\n","reg_input['Stl_per_g'] = combined_teams['Stl']/combined_teams['Game_played']\n","reg_input['Blk_per_g'] = combined_teams['Blk']/combined_teams['Game_played']\n","reg_input['Pf_per_g'] = combined_teams['PF']/combined_teams['Game_played']\n","\n","display(reg_input)\n","display(W_seeds_merge_WTeamConferences)\n","reg_input_tourteams_with_conf = pd.merge(left=reg_input,right=\\\n","                                             W_seeds_merge_WTeamConferences,on=['Season','TeamID'],\\\n","                                                  how='inner')\n","reg_input_tourteams_with_conf.set_index(['Season', 'TeamID'], inplace=True)\n","\n","\n","display(reg_input_tourteams_with_conf)\n","display(reg_input.describe())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:59.315665Z","iopub.status.busy":"2024-03-15T10:22:59.314589Z","iopub.status.idle":"2024-03-15T10:22:59.777220Z","shell.execute_reply":"2024-03-15T10:22:59.775753Z","shell.execute_reply.started":"2024-03-15T10:22:59.315606Z"},"trusted":true},"outputs":[],"source":["seeds_dict = seeds.set_index(['Season', 'TeamID'])\n","tour_comp = pd.read_csv(input_dir+\"WNCAATourneyCompactResults.csv\")\n","#display(tour_comp)\n","tour_input = pd.DataFrame()\n","\n","winners = pd.DataFrame()\n","losers = pd.DataFrame()\n","winners[['Season', 'Team1', 'Team2']] = tour_comp[['Season', 'WTeamID', 'LTeamID']]\n","losers[['Season', 'Team1', 'Team2']] = tour_comp[['Season', 'LTeamID', 'WTeamID']]\n","winners['Result'] = 1\n","losers['Result'] = 0\n","\n","tour_input = pd.concat([winners, losers])\n","tour_input = tour_input[tour_input['Season']>=2010].reset_index(drop = True)\n","\n","t1_seed = []\n","t2_seed = []\n","\n","for x in range(len(tour_input)) : \n","    idx = (tour_input['Season'][x], tour_input['Team1'][x])\n","    seed = seeds_dict.loc[idx].values[0]\n","    if len(seed) == 4:\n","        seed = int(seed[1:-1])\n","    else:\n","        seed = int(seed[1:])\n","    t1_seed.append(seed)\n","    idx = (tour_input['Season'][x], tour_input['Team2'][x])\n","    seed = seeds_dict.loc[idx].values[0]\n","    if len(seed) == 4:\n","        seed = int(seed[1:-1])\n","    else:\n","        seed = int(seed[1:])\n","    t2_seed.append(seed)\n","\n","tour_input['Team1_seed'] = t1_seed\n","tour_input['Team2_seed'] = t2_seed\n","display(tour_input)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:22:59.778984Z","iopub.status.busy":"2024-03-15T10:22:59.778650Z","iopub.status.idle":"2024-03-15T10:23:02.537760Z","shell.execute_reply":"2024-03-15T10:23:02.536319Z","shell.execute_reply.started":"2024-03-15T10:22:59.778954Z"},"trusted":true},"outputs":[],"source":["#can change\n","minus = []\n","\n","for x in range(len(tour_input)):\n","    idx = (tour_input['Season'][x], tour_input['Team1'][x])\n","    team1_score = reg_input_tourteams_with_conf.loc[idx].copy()\n","    team1_score['Seed'] = tour_input['Team1_seed'][x]\n","    \n","    idx = (tour_input['Season'][x], tour_input['Team2'][x])\n","    team2_score = reg_input_tourteams_with_conf.loc[idx].copy()\n","    team2_score['Seed'] = tour_input['Team2_seed'][x]\n","    \n","    outscore = team1_score - team2_score\n","    outscore['Result'] = tour_input['Result'][x]\n","    minus.append(outscore)\n","    \n","minus = pd.DataFrame(minus)\n","display(minus)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:23:02.539624Z","iopub.status.busy":"2024-03-15T10:23:02.539213Z","iopub.status.idle":"2024-03-15T10:23:02.577408Z","shell.execute_reply":"2024-03-15T10:23:02.576090Z","shell.execute_reply.started":"2024-03-15T10:23:02.539590Z"},"trusted":true},"outputs":[],"source":["'''corrs = round(minus.corr(), 2)\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = None\n","#display(np.abs(corrs['Result']))\n","\n","corrs = minus.corr()['Result'].abs().sort_values()\n","display(np.abs(corrs['Result']))\n","# Determine the threshold for the 15% least correlated columns\n","threshold = int(0.15 * len(corrs))\n","\n","\n","least_correlated_features = corrs[:threshold].index.tolist()\n","\n","# Drop the 15% least correlated columns\n","features_to_keep = minus.columns.difference(least_correlated_features)\n","'''\n","pd.options.display.max_columns = 25\n","pd.options.display.max_rows = 25\n","corrs = minus.corr()['Result'].abs().sort_values()\n","display(corrs)  # This will display the sorted correlations.\n","\n","# Determine the threshold for the 15% least correlated columns\n","threshold = int(0.15 * len(corrs))\n","least_correlated_features = corrs[:threshold].index.tolist()\n","\n","# Now you can safely remove the least correlated features\n","features_to_keep = minus.columns.difference(least_correlated_features)\n","\n","# Remove NaN features\n","minus = minus.dropna(axis=1, how='any')\n","features_to_keep = [feature for feature in features_to_keep if feature in minus.columns]\n","number_of_original_features = minus.shape[1] - 1\n","\n","# Continue with your feature scaling and model training...\n","\n","\n","\n","\n","'''import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","plt.figure(figsize=(15,10))\n","sns.heatmap(corrs)\n","plt.show()'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:23:02.579421Z","iopub.status.busy":"2024-03-15T10:23:02.579031Z","iopub.status.idle":"2024-03-15T10:23:03.293415Z","shell.execute_reply":"2024-03-15T10:23:03.292261Z","shell.execute_reply.started":"2024-03-15T10:23:02.579387Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","\n","norm_minus = pd.DataFrame(scaler.fit_transform(minus), columns=minus.columns)\n","norm_minus_filtered = norm_minus[features_to_keep].dropna(axis=1)\n","#X_filtered = norm_minus_filtered[norm_minus_filtered.columns.difference(['Result'])].values\n","\n","X = norm_minus_filtered.drop('Result', axis=1).values\n","y = norm_minus['Result'].values\n","display(minus)\n","display(norm_minus_filtered)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-15T10:23:03.295609Z","iopub.status.busy":"2024-03-15T10:23:03.295205Z","iopub.status.idle":"2024-03-15T10:23:39.951945Z","shell.execute_reply":"2024-03-15T10:23:39.950738Z","shell.execute_reply.started":"2024-03-15T10:23:03.295576Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/lukuanyi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n"]},{"ename":"ImportError","evalue":"cannot import name 'Input' from 'tensorflow.keras.models' (/Users/lukuanyi/Library/Python/3.9/lib/python/site-packages/keras/api/_v2/keras/models/__init__.py)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential, Input, Dense\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Input' from 'tensorflow.keras.models' (/Users/lukuanyi/Library/Python/3.9/lib/python/site-packages/keras/api/_v2/keras/models/__init__.py)"]}],"source":["from tensorflow.keras.models import Sequential, Input, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVR\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LinearRegression\n","import pandas as pd\n","\n","# Assuming X, y and norm_minus_filtered are already defined as per your dataset\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n","X_for_tf = norm_minus_filtered.drop('Result', axis=1)\n","y_for_tf = norm_minus_filtered['Result']\n","X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_for_tf, y_for_tf, test_size=0.2, random_state=9)\n","\n","dtc = DecisionTreeRegressor(criterion='mse', max_depth=5, min_samples_split=10, random_state=9)\n","rfc = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_split=10, random_state=9)\n","svc = SVR(kernel='linear')\n","gnb = GaussianNB()\n","lr = LinearRegression()\n","\n","# Neural network model\n","model = Sequential([\n","    Input(shape=(X_train_tf.shape[1],)),\n","    Dense(32, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(1, activation='linear')  # Changed to linear for regression output\n","])\n","\n","optimizer = Adam(learning_rate=0.0001)\n","model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0.001,\n","    patience=10,\n","    verbose=1,\n","    restore_best_weights=True\n",")\n","\n","# Fit the regression models and make continuous predictions\n","dtc.fit(X_train, y_train)\n","y_pred_dtc_continuous = dtc.predict(X_test)\n","rfc.fit(X_train, y_train)\n","y_pred_rfc_continuous = rfc.predict(X_test)\n","svc.fit(X_train, y_train)\n","y_pred_svc_continuous = svc.predict(X_test)\n","gnb.fit(X_train, y_train)\n","y_pred_gnb_continuous = gnb.predict_proba(X_test)[:, 1]  # Use probability of the positive class\n","lr.fit(X_train, y_train)\n","y_pred_lr_continuous = lr.predict(X_test)\n","\n","# Fit the neural network\n","model.fit(X_train_tf, y_train_tf, epochs=200, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n","y_pred_nn_continuous = model.predict(X_test_tf).flatten()\n","\n","# Convert continuous predictions to binary outcomes\n","y_pred_dtc = (y_pred_dtc_continuous > 0.5).astype(int)\n","y_pred_rfc = (y_pred_rfc_continuous > 0.5).astype(int)\n","y_pred_svc = (y_pred_svc_continuous > 0.5).astype(int)\n","y_pred_gnb = (y_pred_gnb_continuous > 0.5).astype(int)\n","y_pred_lr = (y_pred_lr_continuous > 0.5).astype(int)\n","y_pred_nn = (y_pred_nn_continuous > 0.5).astype(int)\n","\n","def calculate_metrics(y_test, y_pred):\n","    return {\n","        'Accuracy': accuracy_score(y_test, y_pred),\n","        'Precision': precision_score(y_test, y_pred),\n","        'Recall': recall_score(y_test, y_pred),\n","        'F1 Score': f1_score(y_test, y_pred),\n","        'ROC-AUC Score': roc_auc_score(y_test, y_pred)\n","    }\n","\n","# Calculate metrics for each model\n","models_metrics = {\n","    'Linear Regression': calculate_metrics(y_test, y_pred_lr),\n","    'Decision Tree': calculate_metrics(y_test, y_pred_dtc),\n","    'Random Forest': calculate_metrics(y_test, y_pred_rfc),\n","    'Support Vector Regression': calculate_metrics(y_test, y_pred_svc),\n","    'Naive Bayes (Probabilities)': calculate_metrics(y_test, y_pred_gnb),\n","    'Neural Network': calculate_metrics(y_test, y_pred_nn)\n","}\n","\n","# Create a DataFrame from the dictionary\n","df_metrics = pd.DataFrame(models_metrics).T  # Transpose to get models as rows\n","\n","# Display the DataFrame\n","print(df_metrics)\n","\n","\n","\n","\n","\n","'''from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=9)\n","X_for_tf = norm_minus_filtered.drop('Result', axis=1)\n","y_for_tf = norm_minus_filtered['Result']\n","X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(\n","    X_for_tf, y_for_tf, test_size=0.2, random_state=9)\n","\n","\n","\n","\n","dtc = DecisionTreeClassifier(criterion='gini', max_depth = 5, min_samples_split = 10, random_state=9)\n","rfc = RandomForestClassifier(n_estimators=100, max_depth = 5, min_samples_split = 10, random_state=9)  # You can adjust additional parameters here\n","svc = SVC(kernel='linear')  # You can change the kernel based on your dataset characteristics\n","gnb = GaussianNB()\n","lr = LogisticRegression()\n","\n","\n","model = Sequential([\n","    Input(shape=(X_train_tf.shape[1],)),  # Use Input layer to specify input shape\n","    Dense(32, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","optimizer = Adam(learning_rate=0.0001) \n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0.001,\n","    patience=10,\n","    verbose=1,\n","    restore_best_weights=True)\n","\n","dtc.fit(X_train, y_train)\n","y_pred_dtc = dtc.predict(X_test)\n","rfc.fit(X_train, y_train)\n","y_pred_rfc = rfc.predict(X_test)\n","svc.fit(X_train, y_train)\n","y_pred_svc = svc.predict(X_test)\n","gnb.fit(X_train, y_train)\n","y_pred_gnb = gnb.predict(X_test)\n","lr.fit(X_train, y_train)\n","y_pred_lr = lr.predict(X_test)\n","model.fit(\n","    X_train_tf, \n","    y_train_tf, \n","    epochs=200, \n","    batch_size=32, \n","    validation_split=0.2,  \n","    callbacks=[early_stopping])\n","y_pred_nn = model.predict(X_test_tf)\n","\n","\n","def calculate_metrics(y_test, y_pred):\n","    return {\n","        'Accuracy': accuracy_score(y_test, y_pred),\n","        'Precision': precision_score(y_test, y_pred),\n","        'Recall': recall_score(y_test, y_pred),\n","        'F1 Score': f1_score(y_test, y_pred),\n","        'ROC-AUC Score': roc_auc_score(y_test, y_pred)\n","    }\n","\n","# Calculate metrics for each model\n","models_metrics = {\n","    'Linear Regression': calculate_metrics(y_test, y_pred_lr),\n","    'Decision Tree': calculate_metrics(y_test, y_pred_dtc),\n","    'Random Forest': calculate_metrics(y_test, y_pred_rfc),\n","    'Support Vector Classifier': calculate_metrics(y_test, y_pred_svc),\n","    'Gaussian Naive Bayes': calculate_metrics(y_test, y_pred_gnb),\n","    # For the Neural Network, ensure y_pred_nn is properly processed if needed\n","    'Neural Network': calculate_metrics(y_test, y_pred_nn.round())\n","}\n","\n","# Create a DataFrame from the dictionary\n","df_metrics = pd.DataFrame(models_metrics).T  # Transpose to get models as rows\n","\n","# Display the DataFrame\n","print(df_metrics)\n","'''\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7878506,"sourceId":70068,"sourceType":"competition"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
